{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zvAW09stHfK",
        "outputId": "15385041-6758-4b64-93f3-f5630cd636bf"
      },
      "source": [
        "!pip install keras_metrics\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import keras_metrics # for recall and precision metrics\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Embedding, LSTM, Dropout, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_metrics in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras_metrics) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.1.5->keras_metrics) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iSv5KEWtQQz"
      },
      "source": [
        "SEQUENCE_LENGTH = 100 # the length of all sequences (number of words per sample)\n",
        "EMBEDDING_SIZE = 100  # Using 100-Dimensional GloVe embedding vectors\n",
        "TEST_SIZE = 0.25 # ratio of testing set\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20 # number of epochs\n",
        "\n",
        "# to convert labels to integers and vice-versa\n",
        "label2int = {\"ham\": 0, \"spam\": 1}\n",
        "int2label = {0: \"ham\", 1: \"spam\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1yCIj9jtjEa"
      },
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Loads SMS Spam Collection dataset\n",
        "    \"\"\"\n",
        "    texts, labels = [], []\n",
        "    with open(\"/content/drive/MyDrive/SOAI/Data/SMSSpamCollection\") as f:\n",
        "        for line in f:\n",
        "            split = line.split()\n",
        "            labels.append(split[0].strip())\n",
        "            texts.append(' '.join(split[1:]).strip())\n",
        "    return texts, labels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh9vtiGBtrQB"
      },
      "source": [
        "X, y = load_data()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV8AT8BQum8r"
      },
      "source": [
        "# Text tokenization\n",
        "# vectorizing text, turning each text into sequence of integers\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "# convert to sequence of integers\n",
        "X = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvsBOOdGvBdx",
        "outputId": "ed7ff7b7-2b15-406a-b9dd-5a3228e4954f"
      },
      "source": [
        "print(X[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49, 471, 4435, 842, 755, 658, 64, 8, 1327, 88, 123, 351, 1328, 148, 2996, 1329, 67, 58, 4436, 144]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMJ1e9jlvDuV",
        "outputId": "74af6c1f-34cf-41b0-bc5d-1bf6d0084089"
      },
      "source": [
        "# convert to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "# pad sequences at the beginning of each sequence with 0's\n",
        "# for example if SEQUENCE_LENGTH=4:\n",
        "# [[5, 3, 2], [5, 1, 2, 3], [3, 4]]\n",
        "# will be transformed to:\n",
        "# [[0, 5, 3, 2], [5, 1, 2, 3], [0, 0, 3, 4]]\n",
        "X = pad_sequences(X, maxlen=SEQUENCE_LENGTH)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be6OcUTWvIiY"
      },
      "source": [
        "# One Hot encoding labels\n",
        "# [spam, ham, spam, ham, ham] will be converted to:\n",
        "# [1, 0, 1, 0, 1] and then to:\n",
        "# [[0, 1], [1, 0], [0, 1], [1, 0], [0, 1]]\n",
        "\n",
        "y = [ label2int[label] for label in y ]\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk20xy1gvKLh",
        "outputId": "470d9e6d-5f06-4d6a-e2df-f029df6cbd63"
      },
      "source": [
        "print(y[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcD0gHQTvL9a"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=7)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "391lwmtzvSkS"
      },
      "source": [
        "def get_model(tokenizer, lstm_units):\n",
        "    \"\"\"\n",
        "    Constructs the model,\n",
        "    Embedding vectors => LSTM => 2 output Fully-Connected neurons with softmax activation\n",
        "    \"\"\"\n",
        "    # get the GloVe embedding vectors\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(tokenizer.word_index)+1,\n",
        "              EMBEDDING_SIZE,\n",
        "              trainable=False,\n",
        "              input_length=SEQUENCE_LENGTH))\n",
        "\n",
        "    model.add(LSTM(lstm_units, recurrent_dropout=0.2))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(2, activation=\"softmax\"))\n",
        "    # compile as rmsprop optimizer\n",
        "    # aswell as with recall metric\n",
        "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\", keras_metrics.precision(), keras_metrics.recall()])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYR52WwWvcY5",
        "outputId": "273efda6-9262-4751-8f6b-63c189900d38"
      },
      "source": [
        "# constructs the model with 128 LSTM units\n",
        "model = get_model(tokenizer=tokenizer, lstm_units=128)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          901000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               117248    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,018,506\n",
            "Trainable params: 117,506\n",
            "Non-trainable params: 901,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BDK6NlNvh7h",
        "outputId": "9e7c73c1-427d-476e-e9cc-44d42a04c194"
      },
      "source": [
        "# constructs the model with 128 LSTM units\n",
        "model = get_model(tokenizer=tokenizer, lstm_units=128)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 100)          901000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               117248    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,018,506\n",
            "Trainable params: 117,506\n",
            "Non-trainable params: 901,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6xN002SxB-i",
        "outputId": "8e32cdce-cd80-45e5-bf24-f74dd042c2a7"
      },
      "source": [
        "# initialize our ModelCheckpoint and TensorBoard callbacks\n",
        "# model checkpoint for saving best weights\n",
        "model_checkpoint = ModelCheckpoint(\"results/spam_classifier_{val_loss:.2f}\", save_best_only=True,\n",
        "                                    verbose=1)\n",
        "# for better visualization\n",
        "tensorboard = TensorBoard(f\"logs/spam_classifier_{time.time()}\")\n",
        "# print our data shapes\n",
        "print(\"X_train.shape:\", X_train.shape)\n",
        "print(\"X_test.shape:\", X_test.shape)\n",
        "print(\"y_train.shape:\", y_train.shape)\n",
        "print(\"y_test.shape:\", y_test.shape)\n",
        "# train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "          batch_size=BATCH_SIZE, epochs=EPOCHS)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape: (4180, 100)\n",
            "X_test.shape: (1394, 100)\n",
            "y_train.shape: (4180, 2)\n",
            "y_test.shape: (1394, 2)\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1402: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.4105 - accuracy: 0.8450 - precision: 0.8738 - recall: 0.9150WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "66/66 [==============================] - 24s 318ms/step - loss: 0.4093 - accuracy: 0.8453 - precision: 0.8738 - recall: 0.9157 - val_loss: 0.2806 - val_accuracy: 0.8615 - val_precision: 0.8650 - val_recall: 1.0000\n",
            "Epoch 2/20\n",
            "66/66 [==============================] - 20s 307ms/step - loss: 0.2645 - accuracy: 0.8892 - precision: 0.8924 - recall: 0.9971 - val_loss: 0.2524 - val_accuracy: 0.8730 - val_precision: 0.8762 - val_recall: 1.0000\n",
            "Epoch 3/20\n",
            "66/66 [==============================] - 20s 308ms/step - loss: 0.2328 - accuracy: 0.9109 - precision: 0.9017 - recall: 0.9876 - val_loss: 0.2565 - val_accuracy: 0.8745 - val_precision: 0.8747 - val_recall: 1.0000\n",
            "Epoch 4/20\n",
            "66/66 [==============================] - 21s 311ms/step - loss: 0.1774 - accuracy: 0.9402 - precision: 0.9434 - recall: 0.9891 - val_loss: 0.3339 - val_accuracy: 0.8644 - val_precision: 0.8669 - val_recall: 1.0000\n",
            "Epoch 5/20\n",
            "66/66 [==============================] - 21s 312ms/step - loss: 0.1986 - accuracy: 0.9295 - precision: 0.9424 - recall: 0.9832 - val_loss: 0.1598 - val_accuracy: 0.9462 - val_precision: 0.9601 - val_recall: 0.9791\n",
            "Epoch 6/20\n",
            "66/66 [==============================] - 20s 310ms/step - loss: 0.1878 - accuracy: 0.9298 - precision: 0.9501 - recall: 0.9871 - val_loss: 0.1600 - val_accuracy: 0.9527 - val_precision: 0.9601 - val_recall: 0.9829\n",
            "Epoch 7/20\n",
            "66/66 [==============================] - 21s 315ms/step - loss: 0.1498 - accuracy: 0.9484 - precision: 0.9554 - recall: 0.9824 - val_loss: 0.1831 - val_accuracy: 0.9326 - val_precision: 0.9723 - val_recall: 0.9442\n",
            "Epoch 8/20\n",
            "66/66 [==============================] - 20s 311ms/step - loss: 0.1467 - accuracy: 0.9526 - precision: 0.9641 - recall: 0.9814 - val_loss: 0.1517 - val_accuracy: 0.9448 - val_precision: 0.9715 - val_recall: 0.9645\n",
            "Epoch 9/20\n",
            "66/66 [==============================] - 20s 309ms/step - loss: 0.1360 - accuracy: 0.9516 - precision: 0.9629 - recall: 0.9783 - val_loss: 0.2311 - val_accuracy: 0.9168 - val_precision: 0.9789 - val_recall: 0.9293\n",
            "Epoch 10/20\n",
            "66/66 [==============================] - 21s 314ms/step - loss: 0.1388 - accuracy: 0.9538 - precision: 0.9721 - recall: 0.9701 - val_loss: 0.1436 - val_accuracy: 0.9555 - val_precision: 0.9675 - val_recall: 0.9831\n",
            "Epoch 11/20\n",
            "66/66 [==============================] - 21s 313ms/step - loss: 0.1173 - accuracy: 0.9632 - precision: 0.9699 - recall: 0.9879 - val_loss: 0.1482 - val_accuracy: 0.9534 - val_precision: 0.9491 - val_recall: 0.9978\n",
            "Epoch 12/20\n",
            "66/66 [==============================] - 21s 313ms/step - loss: 0.1170 - accuracy: 0.9586 - precision: 0.9625 - recall: 0.9897 - val_loss: 0.1447 - val_accuracy: 0.9469 - val_precision: 0.9732 - val_recall: 0.9640\n",
            "Epoch 13/20\n",
            "66/66 [==============================] - 20s 310ms/step - loss: 0.1141 - accuracy: 0.9622 - precision: 0.9724 - recall: 0.9831 - val_loss: 0.1246 - val_accuracy: 0.9605 - val_precision: 0.9688 - val_recall: 0.9865\n",
            "Epoch 14/20\n",
            "66/66 [==============================] - 20s 306ms/step - loss: 0.1078 - accuracy: 0.9642 - precision: 0.9774 - recall: 0.9910 - val_loss: 0.1380 - val_accuracy: 0.9455 - val_precision: 0.9712 - val_recall: 0.9665\n",
            "Epoch 15/20\n",
            "66/66 [==============================] - 21s 312ms/step - loss: 0.1003 - accuracy: 0.9669 - precision: 0.9770 - recall: 0.9893 - val_loss: 0.1574 - val_accuracy: 0.9448 - val_precision: 0.9696 - val_recall: 0.9613\n",
            "Epoch 16/20\n",
            "66/66 [==============================] - 21s 320ms/step - loss: 0.1091 - accuracy: 0.9657 - precision: 0.9772 - recall: 0.9879 - val_loss: 0.1340 - val_accuracy: 0.9613 - val_precision: 0.9613 - val_recall: 0.9964\n",
            "Epoch 17/20\n",
            "66/66 [==============================] - 21s 321ms/step - loss: 0.1049 - accuracy: 0.9647 - precision: 0.9684 - recall: 0.9880 - val_loss: 0.1322 - val_accuracy: 0.9491 - val_precision: 0.9709 - val_recall: 0.9681\n",
            "Epoch 18/20\n",
            "66/66 [==============================] - 21s 321ms/step - loss: 0.0931 - accuracy: 0.9740 - precision: 0.9798 - recall: 0.9937 - val_loss: 0.1849 - val_accuracy: 0.9333 - val_precision: 0.9762 - val_recall: 0.9467\n",
            "Epoch 19/20\n",
            "66/66 [==============================] - 21s 321ms/step - loss: 0.1066 - accuracy: 0.9667 - precision: 0.9744 - recall: 0.9867 - val_loss: 0.1577 - val_accuracy: 0.9462 - val_precision: 0.9410 - val_recall: 0.9990\n",
            "Epoch 20/20\n",
            "66/66 [==============================] - 21s 325ms/step - loss: 0.0984 - accuracy: 0.9661 - precision: 0.9582 - recall: 0.9921 - val_loss: 0.1241 - val_accuracy: 0.9584 - val_precision: 0.9737 - val_recall: 0.9792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f938ef2f5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RDkTC0rzXl7",
        "outputId": "80f79388-e452-441c-8b19-13efc20aa776"
      },
      "source": [
        "# get the loss and metrics\n",
        "result = model.evaluate(X_test, y_test)\n",
        "# extract those\n",
        "loss = result[0]\n",
        "accuracy = result[1]\n",
        "precision = result[2]\n",
        "recall = result[3]\n",
        "\n",
        "print(f\"[+] Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"[+] Precision:   {precision*100:.2f}%\")\n",
        "print(f\"[+] Recall:   {recall*100:.2f}%\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 2s 37ms/step - loss: 0.1241 - accuracy: 0.9584 - precision: 0.9745 - recall: 0.9793\n",
            "[+] Accuracy: 95.84%\n",
            "[+] Precision:   97.45%\n",
            "[+] Recall:   97.93%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UXANmU2zAAY"
      },
      "source": [
        "def get_predictions(text):\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    # pad the sequence\n",
        "    sequence = pad_sequences(sequence, maxlen=SEQUENCE_LENGTH)\n",
        "    # get the prediction\n",
        "    prediction = model.predict(sequence)[0]\n",
        "    # one-hot encoded vector, revert using np.argmax\n",
        "    return int2label[np.argmax(prediction)]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp_xygByzbsm",
        "outputId": "573a9e32-950f-4510-d6fa-0a6ce0cff911"
      },
      "source": [
        "text = \"Congrats! double your mins txts on orange or 1 2 price linerental motorola and sonyericsson with b tooth free nokia free call\"\n",
        "print(get_predictions(text))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBUeLq9hzdUL",
        "outputId": "716a00da-9155-4ffd-af5e-59e847b47a2b"
      },
      "source": [
        "text = \"Hi man, I was wondering if we can meet tomorrow.\"\n",
        "print(get_predictions(text))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ham\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI5-eu1j7w4B"
      },
      "source": [
        "ref: https://www.thepythoncode.com/article/build-spam-classifier-keras-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhXpd2lB7Mpu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}